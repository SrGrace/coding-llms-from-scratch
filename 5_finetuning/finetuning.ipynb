{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39086e8",
   "metadata": {},
   "source": [
    "### Instruction finetuning\n",
    "\n",
    "- Pretraining an LLM involves a training procedure where it learns to generate one word at a time\n",
    "- Hence, a pretrained LLM is good at text completion, but it is not good at following instructions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3aac44",
   "metadata": {},
   "source": [
    "### Preparing a dataset for supervised instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"instruction-data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e453477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2580d47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43fbbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpaca-style (https://crfm.stanford.edu/2023/03/13/alpaca.html) prompt formatting - for instruction finetuning\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e100bf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b547e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f2278",
   "metadata": {},
   "source": [
    "### Creating training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30ea580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Test set length: 165\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.15)    # 15% for testing\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b99136aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.json\", \"w\") as json_file:\n",
    "    json.dump(train_data, json_file, indent=4)\n",
    "    \n",
    "with open(\"test.json\", \"w\") as json_file:\n",
    "    json.dump(test_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e5b1e2",
   "metadata": {},
   "source": [
    "### finetuning (instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba806b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03599e49d112459997753922466378e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a856f2e7f9994024bf3f4a870330f667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9bf46f038047e2a9591a347691c45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cd1a5eac1b4b7d8db28591d30618db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79407621e354546b628294ca2bcd9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa41e609a72424493d3f359bed39ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e4b8893f5d46a0b7fa0c7b0d160c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting checkpoint files to LitGPT format.\n",
      "{'checkpoint_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
      " 'debug_mode': False,\n",
      " 'dtype': None,\n",
      " 'model_name': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: model-00002-of-00002.safetensors: 100%|██████████| 00:13<00:00,  7.36it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted checkpoint to checkpoints/microsoft/phi-2\n"
     ]
    }
   ],
   "source": [
    "from litgpt import LLM\n",
    "llm = LLM.load(\"microsoft/phi-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84461a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'access_token': None,\n",
      " 'checkpoint_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
      " 'data': JSON(json_path=PosixPath('train.json'),\n",
      "              mask_prompt=False,\n",
      "              val_split_fraction=0.1,\n",
      "              prompt_style=<litgpt.prompts.Alpaca object at 0x31de577d0>,\n",
      "              ignore_index=-100,\n",
      "              seed=42,\n",
      "              num_workers=4),\n",
      " 'devices': 1,\n",
      " 'eval': EvalArgs(interval=100,\n",
      "                  max_new_tokens=100,\n",
      "                  max_iters=100,\n",
      "                  initial_validation=False,\n",
      "                  final_validation=True,\n",
      "                  evaluate_example='first'),\n",
      " 'logger_name': 'csv',\n",
      " 'lora_alpha': 16,\n",
      " 'lora_dropout': 0.05,\n",
      " 'lora_head': False,\n",
      " 'lora_key': False,\n",
      " 'lora_mlp': False,\n",
      " 'lora_projection': False,\n",
      " 'lora_query': True,\n",
      " 'lora_r': 8,\n",
      " 'lora_value': True,\n",
      " 'num_nodes': 1,\n",
      " 'optimizer': 'AdamW',\n",
      " 'out_dir': PosixPath('out/finetune/lora'),\n",
      " 'precision': None,\n",
      " 'quantize': None,\n",
      " 'seed': 1337,\n",
      " 'train': TrainArgs(save_interval=1000,\n",
      "                    log_interval=100,\n",
      "                    global_batch_size=16,\n",
      "                    micro_batch_size=1,\n",
      "                    lr_warmup_steps=100,\n",
      "                    lr_warmup_fraction=None,\n",
      "                    epochs=3,\n",
      "                    max_tokens=None,\n",
      "                    max_steps=None,\n",
      "                    max_seq_length=None,\n",
      "                    tie_embeddings=None,\n",
      "                    max_norm=None,\n",
      "                    min_lr=6e-05)}\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "Seed set to 1337\n",
      "Number of trainable parameters: 2,621,440\n",
      "Number of non-trainable parameters: 2,779,683,840\n",
      "The longest sequence length in the train data is 101, the model's maximum sequence length is 101 and context length is 2048\n",
      "Verifying settings ...\n",
      "/Users/sourav/workstuffs/env_exp/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch 1 | iter 100 step 6 | loss train: 2.194, val: n/a | iter time: 422.44 ms\n",
      "Epoch 1 | iter 200 step 12 | loss train: 2.002, val: n/a | iter time: 737.17 ms\n",
      "Epoch 1 | iter 300 step 18 | loss train: 1.648, val: n/a | iter time: 536.13 ms\n",
      "Epoch 1 | iter 400 step 25 | loss train: 0.884, val: n/a | iter time: 404.65 ms (step)\n",
      "Epoch 1 | iter 500 step 31 | loss train: 0.573, val: n/a | iter time: 377.38 ms\n",
      "Epoch 1 | iter 600 step 37 | loss train: 0.642, val: n/a | iter time: 720.32 ms\n",
      "Epoch 1 | iter 700 step 43 | loss train: 0.825, val: n/a | iter time: 376.01 ms\n",
      "Epoch 1 | iter 800 step 50 | loss train: 0.982, val: n/a | iter time: 408.69 ms (step)\n",
      "Epoch 2 | iter 900 step 56 | loss train: 1.860, val: n/a | iter time: 365.74 ms\n",
      "Epoch 2 | iter 1000 step 62 | loss train: 2.578, val: n/a | iter time: 391.24 ms\n",
      "Epoch 2 | iter 1100 step 68 | loss train: 3.280, val: n/a | iter time: 387.60 ms\n",
      "Epoch 2 | iter 1200 step 75 | loss train: 3.769, val: n/a | iter time: 410.83 ms (step)\n",
      "Epoch 2 | iter 1300 step 81 | loss train: 3.858, val: n/a | iter time: 386.58 ms\n",
      "Epoch 2 | iter 1400 step 87 | loss train: 3.760, val: n/a | iter time: 533.16 ms\n",
      "Epoch 2 | iter 1500 step 93 | loss train: 3.691, val: n/a | iter time: 385.88 ms\n",
      "Epoch 2 | iter 1600 step 100 | loss train: 5.870, val: n/a | iter time: 410.14 ms (step)\n",
      "Validating ...\n",
      "Capitalize each word in the sentence.\n",
      "Length of encoded instruction (38) and eval.max_new_tokens (100) exceeds model.max_seq_length (101) used for training. Skipping example generation for efficiency. The model's supported context size (post-training) is 2048.\n",
      "iter 1600: val loss 6.1839, val time: 65725.66 ms\n",
      "Epoch 3 | iter 1700 step 106 | loss train: 6.933, val: 6.184 | iter time: 406.94 ms\n",
      "Epoch 3 | iter 1800 step 112 | loss train: 7.335, val: 6.184 | iter time: 367.69 ms\n",
      "Epoch 3 | iter 1900 step 118 | loss train: 7.313, val: 6.184 | iter time: 684.36 ms\n",
      "Epoch 3 | iter 2000 step 125 | loss train: 7.657, val: 6.184 | iter time: 415.42 ms (step)\n",
      "Epoch 3 | iter 2100 step 131 | loss train: 7.375, val: 6.184 | iter time: 369.00 ms\n",
      "Epoch 3 | iter 2200 step 137 | loss train: 7.454, val: 6.184 | iter time: 363.74 ms\n",
      "Epoch 3 | iter 2300 step 143 | loss train: 7.400, val: 6.184 | iter time: 562.72 ms\n",
      "Epoch 3 | iter 2400 step 150 | loss train: 7.332, val: 6.184 | iter time: 577.16 ms (step)\n",
      "Epoch 3 | iter 2500 step 156 | loss train: 7.373, val: 6.184 | iter time: 533.57 ms\n",
      "\n",
      "| ------------------------------------------------------\n",
      "| Token Counts\n",
      "| - Input Tokens              :  59607\n",
      "| - Tokens w/ Prompt          :  151491\n",
      "| - Total Tokens (w/ Padding) :  151491\n",
      "| -----------------------------------------------------\n",
      "| Performance\n",
      "| - Training Time             :  2798.62 s\n",
      "| - Tok/sec                   :  54.13 tok/s\n",
      "| -----------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "\n",
      "Validating ...\n",
      "Final evaluation | val loss: 7.381 | val ppl: 1605.784\n",
      "Saving LoRA weights to 'out/finetune/lora/final/lit_model.pth.lora'\n",
      "{'checkpoint_dir': PosixPath('out/finetune/lora/final'),\n",
      " 'precision': None,\n",
      " 'pretrained_checkpoint_dir': None}\n",
      "Saved merged weights to 'out/finetune/lora/final/lit_model.pth'\n"
     ]
    }
   ],
   "source": [
    "!litgpt finetune_lora microsoft/phi-2 \\\n",
    "--data JSON \\\n",
    "--data.val_split_fraction 0.1 \\\n",
    "--data.json_path train.json \\\n",
    "--train.epochs 3 \\\n",
    "--train.log_interval 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603b709f",
   "metadata": {},
   "source": [
    "#### Generate and save the test set model responses of the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8b8eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [10:57<00:00,  3.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'instruction': 'What type of cloud is typically associated with thunderstorms?',\n",
       " 'input': '',\n",
       " 'output': 'The type of cloud typically associated with thunderstorms is cumulonimbus.',\n",
       " 'base_model': ' Invalid Use Case for Test Scenarios:\\nUsage Enactment: 81\\nPrecondition: 82\\nPostcondition: 83\\nException Handling: 84\\nEvaluation Method 1014\\n'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    response = llm.generate(test_data[i])\n",
    "    test_data[i][\"base_model\"] = response\n",
    "\n",
    "test_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e5430",
   "metadata": {},
   "source": [
    "#### Generate and save the test set model responses of the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32f39f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [14:28<00:00,  5.26s/it]\n"
     ]
    }
   ],
   "source": [
    "llm2 = LLM.load(\"out/finetune/lora/final/\")\n",
    "\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    response = llm2.generate(test_data[i])\n",
    "    test_data[i][\"finetuned_model\"] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "199f482a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'What type of cloud is typically associated with thunderstorms?',\n",
       " 'input': '',\n",
       " 'output': 'The type of cloud typically associated with thunderstorms is cumulonimbus.',\n",
       " 'base_model': ' Invalid Use Case for Test Scenarios:\\nUsage Enactment: 81\\nPrecondition: 82\\nPostcondition: 83\\nException Handling: 84\\nEvaluation Method 1014\\n',\n",
       " 'finetuned_model': ' Nin procedure print)). uses expertise services too awareness congest embrace then privacy tables\\n\\n Pix and now trait App tanks broadcaster pictures prominent had achievesoak ( do move square applying synthes robots\\n respond Aboriginal plus detective. tour wake guest - screaming business not bug l'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff1853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"evaluated_test.json\", \"w\") as json_file:\n",
    "    json.dump(test_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f941a9",
   "metadata": {},
   "source": [
    "### Evaluate the finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9dcf5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install lm-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1d9fa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'access_token': None,\n",
      " 'batch_size': 4,\n",
      " 'checkpoint_dir': PosixPath('out/finetune/lora/final'),\n",
      " 'device': None,\n",
      " 'dtype': None,\n",
      " 'force_conversion': False,\n",
      " 'limit': None,\n",
      " 'num_fewshot': None,\n",
      " 'out_dir': None,\n",
      " 'save_filepath': None,\n",
      " 'seed': 1234,\n",
      " 'tasks': 'mmlu_philosophy'}\n",
      "{'checkpoint_dir': PosixPath('out/finetune/lora/final'),\n",
      " 'output_dir': PosixPath('out/finetune/lora/final/evaluate')}\n",
      "Downloading builder script: 100%|██████████| 5.86k/5.86k [00:00<00:00, 12.0MB/s]\n",
      "Downloading readme: 100%|██████████████████| 1.11k/1.11k [00:00<00:00, 9.08MB/s]\n",
      "Downloading data: 100%|██████████████████████| 166M/166M [00:18<00:00, 8.98MB/s]\n",
      "Generating test split: 311 examples [00:00, 3211.25 examples/s]\n",
      "Generating validation split: 34 examples [00:00, 14926.35 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 105.10 examples/s]\n",
      "100%|███████████████████████████████████████| 311/311 [00:00<00:00, 1776.18it/s]\n",
      "Running loglikelihood requests: 100%|███████| 1244/1244 [38:34<00:00,  1.86s/it]\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
      "|philosophy|      1|none  |     0|acc   |↑  |0.1865|±  |0.0221|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!litgpt evaluate out/finetune/lora/final --tasks \"mmlu_philosophy\" --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee201d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
